\name{GMMN_trained}
% Trained neural networks
\alias{GMMN_dim_2_300_2_ntrn_60000_nbat_5000_nepo_300_C_tau_0.25}
\alias{GMMN_dim_2_300_2_ntrn_60000_nbat_5000_nepo_300_C_tau_0.5}
\alias{GMMN_dim_2_300_2_ntrn_60000_nbat_5000_nepo_300_C_tau_0.75}
\alias{GMMN_dim_2_300_2_ntrn_60000_nbat_5000_nepo_300_G_tau_0.25}
\alias{GMMN_dim_2_300_2_ntrn_60000_nbat_5000_nepo_300_G_tau_0.5}
\alias{GMMN_dim_2_300_2_ntrn_60000_nbat_5000_nepo_300_G_tau_0.75}
\alias{GMMN_dim_2_300_2_ntrn_60000_nbat_5000_nepo_300_eqmix_C_tau_0.5_rot90_t4_tau_0.5}
\alias{GMMN_dim_2_300_2_ntrn_60000_nbat_5000_nepo_300_eqmix_G_tau_0.5_rot90_t4_tau_0.5}
\alias{GMMN_dim_2_300_2_ntrn_60000_nbat_5000_nepo_300_eqmix_MO_0.75_0.6_rot90_t4_tau_0.5}
\alias{GMMN_dim_2_300_2_ntrn_60000_nbat_5000_nepo_300_MO_0.75_0.6}
\alias{GMMN_dim_2_300_2_ntrn_60000_nbat_5000_nepo_300_t4_tau_0.25}
\alias{GMMN_dim_2_300_2_ntrn_60000_nbat_5000_nepo_300_t4_tau_0.5}
\alias{GMMN_dim_2_300_2_ntrn_60000_nbat_5000_nepo_300_t4_tau_0.75}
\alias{GMMN_dim_3_300_3_ntrn_60000_nbat_5000_nepo_300_NC21_tau_0.25_0.5}
\alias{GMMN_dim_3_300_3_ntrn_60000_nbat_5000_nepo_300_NG21_tau_0.25_0.5}
\alias{GMMN_dim_5_300_5_ntrn_60000_nbat_5000_nepo_300_C_tau_0.5}
\alias{GMMN_dim_5_300_5_ntrn_60000_nbat_5000_nepo_300_G_tau_0.5}
\alias{GMMN_dim_5_300_5_ntrn_60000_nbat_5000_nepo_300_NC23_tau_0.25_0.5_0.75}
\alias{GMMN_dim_5_300_5_ntrn_60000_nbat_5000_nepo_300_NG23_tau_0.25_0.5_0.75}
\alias{GMMN_dim_5_300_5_ntrn_60000_nbat_5000_nepo_300_t4_tau_0.5}
\alias{GMMN_dim_10_300_10_ntrn_60000_nbat_5000_nepo_300_C_tau_0.5}
\alias{GMMN_dim_10_300_10_ntrn_60000_nbat_5000_nepo_300_G_tau_0.5}
\alias{GMMN_dim_10_300_10_ntrn_60000_nbat_5000_nepo_300_NC55_tau_0.25_0.5_0.75}
\alias{GMMN_dim_10_300_10_ntrn_60000_nbat_5000_nepo_300_NG55_tau_0.25_0.5_0.75}
\alias{GMMN_dim_10_300_10_ntrn_60000_nbat_5000_nepo_300_t4_tau_0.5}
\title{Trained Generative Moment Matching Networks}
\description{
  Trained generative moment matching networks (GMMNs); see also
  the demo \code{GMMN_QMC} or the vignette \code{GMMN_QMC}.
}
\usage{
% Trained neural networks
data("GMMN_dim_2_300_2_ntrn_60000_nbat_5000_nepo_300_C_tau_0.25")
data("GMMN_dim_2_300_2_ntrn_60000_nbat_5000_nepo_300_C_tau_0.5")
data("GMMN_dim_2_300_2_ntrn_60000_nbat_5000_nepo_300_C_tau_0.75")
data("GMMN_dim_2_300_2_ntrn_60000_nbat_5000_nepo_300_G_tau_0.25")
data("GMMN_dim_2_300_2_ntrn_60000_nbat_5000_nepo_300_G_tau_0.5")
data("GMMN_dim_2_300_2_ntrn_60000_nbat_5000_nepo_300_G_tau_0.75")
data("GMMN_dim_2_300_2_ntrn_60000_nbat_5000_nepo_300_eqmix_C_tau_0.5_rot90_t4_tau_0.5")
data("GMMN_dim_2_300_2_ntrn_60000_nbat_5000_nepo_300_eqmix_G_tau_0.5_rot90_t4_tau_0.5")
data("GMMN_dim_2_300_2_ntrn_60000_nbat_5000_nepo_300_eqmix_MO_0.75_0.6_rot90_t4_tau_0.5")
data("GMMN_dim_2_300_2_ntrn_60000_nbat_5000_nepo_300_MO_0.75_0.6")
data("GMMN_dim_2_300_2_ntrn_60000_nbat_5000_nepo_300_t4_tau_0.25")
data("GMMN_dim_2_300_2_ntrn_60000_nbat_5000_nepo_300_t4_tau_0.5")
data("GMMN_dim_2_300_2_ntrn_60000_nbat_5000_nepo_300_t4_tau_0.75")
data("GMMN_dim_3_300_3_ntrn_60000_nbat_5000_nepo_300_NC21_tau_0.25_0.5")
data("GMMN_dim_3_300_3_ntrn_60000_nbat_5000_nepo_300_NG21_tau_0.25_0.5")
data("GMMN_dim_5_300_5_ntrn_60000_nbat_5000_nepo_300_C_tau_0.5")
data("GMMN_dim_5_300_5_ntrn_60000_nbat_5000_nepo_300_G_tau_0.5")
data("GMMN_dim_5_300_5_ntrn_60000_nbat_5000_nepo_300_NC23_tau_0.25_0.5_0.75")
data("GMMN_dim_5_300_5_ntrn_60000_nbat_5000_nepo_300_NG23_tau_0.25_0.5_0.75")
data("GMMN_dim_5_300_5_ntrn_60000_nbat_5000_nepo_300_t4_tau_0.5")
data("GMMN_dim_10_300_10_ntrn_60000_nbat_5000_nepo_300_C_tau_0.5")
data("GMMN_dim_10_300_10_ntrn_60000_nbat_5000_nepo_300_G_tau_0.5")
data("GMMN_dim_10_300_10_ntrn_60000_nbat_5000_nepo_300_NC55_tau_0.25_0.5_0.75")
data("GMMN_dim_10_300_10_ntrn_60000_nbat_5000_nepo_300_NG55_tau_0.25_0.5_0.75")
data("GMMN_dim_10_300_10_ntrn_60000_nbat_5000_nepo_300_t4_tau_0.5")
}
\format{
  % Trained neural networks
  \describe{
    \item{GMMN_dim_2_300_2_ntrn_60000_nbat_5000_nepo_300_C_tau_0.25}{
      \code{\link{raw}} \R object representing a GMMN (input and output
      layer are two-dimensional, the single hidden layer is
      300-dimensional) trained on 60000 pseudo-samples (with batch size 5000 and
      300 epochs) from a bivariate Clayton
      copula (with parameter chosen such that Kendall's tau equals 0.25).
    }
    \item{GMMN_dim_2_300_2_ntrn_60000_nbat_5000_nepo_300_C_tau_0.5}{
      \code{\link{raw}} \R object representing a GMMN (input and output
      layer are two-dimensional, the single hidden layer is
      300-dimensional) trained on 60000 pseudo-samples (with batch size 5000 and
      300 epochs) from a bivariate Clayton
      copula (with parameter chosen such that Kendall's tau equals 0.5).
    }
    \item{GMMN_dim_2_300_2_ntrn_60000_nbat_5000_nepo_300_C_tau_0.75}{
      \code{\link{raw}} \R object representing a GMMN (input and output
      layer are two-dimensional, the single hidden layer is
      300-dimensional) trained on 60000 pseudo-samples (with batch size 5000 and
      300 epochs) from a bivariate Clayton
      copula (with parameter chosen such that Kendall's tau equals 0.75).
    }
    \item{GMMN_dim_2_300_2_ntrn_60000_nbat_5000_nepo_300_G_tau_0.25}{
      \code{\link{raw}} \R object representing a GMMN (input and output
      layer are two-dimensional, the single hidden layer is
      300-dimensional) trained on 60000 pseudo-samples (with batch size 5000 and
      300 epochs) from a bivariate Gumbel
      copula (with parameter chosen such that Kendall's tau equals 0.25).
    }
    \item{GMMN_dim_2_300_2_ntrn_60000_nbat_5000_nepo_300_G_tau_0.5}{
      \code{\link{raw}} \R object representing a GMMN (input and output
      layer are two-dimensional, the single hidden layer is
      300-dimensional) trained on 60000 pseudo-samples (with batch size 5000 and
      300 epochs) from a bivariate Gumbel
      copula (with parameter chosen such that Kendall's tau equals 0.5).
    }
    \item{GMMN_dim_2_300_2_ntrn_60000_nbat_5000_nepo_300_G_tau_0.75}{
      \code{\link{raw}} \R object representing a GMMN (input and output
      layer are two-dimensional, the single hidden layer is
      300-dimensional) trained on 60000 pseudo-samples (with batch size 5000 and
      300 epochs) from a bivariate Gumbel
      copula (with parameter chosen such that Kendall's tau equals 0.75).
    }
    \item{GMMN_dim_2_300_2_ntrn_60000_nbat_5000_nepo_300_eqmix_C_tau_0.5_rot90_t4_tau_0.5}{
      \code{\link{raw}} \R object representing a GMMN (input and output
      layer are two-dimensional, the single hidden layer is
      300-dimensional) trained on 60000 pseudo-samples (with batch size 5000 and
      300 epochs) from a bivariate half-half mixture of a Clayton
      copula (with parameter chosen such that Kendall's tau equals 0.5)
      and a rotated (by 90 degree) $t$ copula (with 4 degrees of freedom
      and correlation parameter chosen such that Kendall's tau equals
      0.5); see \code{vignette("GMMN_QRNG", package = "gnn")}.
    }
    \item{GMMN_dim_2_300_2_ntrn_60000_nbat_5000_nepo_300_eqmix_G_tau_0.5_rot90_t4_tau_0.5}{
      \code{\link{raw}} \R object representing a GMMN (input and output
      layer are two-dimensional, the single hidden layer is
      300-dimensional) trained on 60000 pseudo-samples (with batch size 5000 and
      300 epochs) from a bivariate half-half mixture of a Gumbel
      copula (with parameter chosen such that Kendall's tau equals 0.5)
      and a rotated (by 90 degree) $t$ copula (with 4 degrees of freedom
      and correlation parameter chosen such that Kendall's tau equals
      0.5).
    }
    \item{GMMN_dim_2_300_2_ntrn_60000_nbat_5000_nepo_300_eqmix_MO_0.75_0.6_rot90_t4_tau_0.5}{
      \code{\link{raw}} \R object representing a GMMN (input and output
      layer are two-dimensional, the single hidden layer is
      300-dimensional) trained on 60000 pseudo-samples (with batch size 5000 and
      300 epochs) from a bivariate half-half mixture of a Marshall--Olkin
      copula (with \eqn{\alpha_{1}=0.75}{alpha_1 = 0.75} and
      \eqn{\alpha_{2}=0.60}{alpha_2 = 0.60})
      and a rotated (by 90 degree) $t$ copula (with 4 degrees of freedom
      and correlation parameter chosen such that Kendall's tau equals
      0.5).
    }
    \item{GMMN_dim_2_300_2_ntrn_60000_nbat_5000_nepo_300_MO_0.75_0.6}{
      \code{\link{raw}} \R object representing a GMMN (input and output
      layer are two-dimensional, the single hidden layer is
      300-dimensional) trained on 60000 pseudo-samples (with batch size 5000 and
      300 epochs) from a Marshall--Olkin
      copula (with \eqn{\alpha_{1}=0.75}{alpha_1=0.75} and
      \eqn{\alpha_{2}=0.60}{alpha_2=0.60}).
    }
    \item{GMMN_dim_2_300_2_ntrn_60000_nbat_5000_nepo_300_t4_tau_0.25}{
      \code{\link{raw}} \R object representing a GMMN (input and output
      layer are two-dimensional, the single hidden layer is
      300-dimensional) trained on 60000 pseudo-samples (with batch size 5000 and
      300 epochs) from a two-dimensional $t$ copula (with 4 degrees of freedom
      and equi-correlation parameter chosen such that Kendall's tau equals
      0.25).
    }
    \item{GMMN_dim_2_300_2_ntrn_60000_nbat_5000_nepo_300_t4_tau_0.5}{
      \code{\link{raw}} \R object representing a GMMN (input and output
      layer are two-dimensional, the single hidden layer is
      300-dimensional) trained on 60000 pseudo-samples (with batch size 5000 and
      300 epochs) from a two-dimensional $t$ copula (with 4 degrees of freedom
      and equi-correlation parameter chosen such that Kendall's tau equals
      0.5).
    }
    \item{GMMN_dim_2_300_2_ntrn_60000_nbat_5000_nepo_300_t4_tau_0.75}{
      \code{\link{raw}} \R object representing a GMMN (input and output
      layer are two-dimensional, the single hidden layer is
      300-dimensional) trained on 60000 pseudo-samples (with batch size 5000 and
      300 epochs) from a two-dimensional $t$ copula (with 4 degrees of freedom
      and equi-correlation parameter chosen such that Kendall's tau equals
      0.75).
    }
    \item{GMMN_dim_3_300_3_ntrn_60000_nbat_5000_nepo_300_NC21_tau_0.25_0.5}{
      \code{\link{raw}} \R object representing a GMMN (input and output
      layer are three-dimensional, the single hidden layer is
      300-dimensional) trained on 60000 pseudo-samples (with batch size 5000 and
      300 epochs) from a three-dimensional nested Clayton copula
      (with sector dimensions 2 and 1, corresponding Kendall's tau 0.5
      within the first sector and Kendall's tau 0.25 between the two sectors).
    }
    \item{GMMN_dim_3_300_3_ntrn_60000_nbat_5000_nepo_300_NG21_tau_0.25_0.5}{
      \code{\link{raw}} \R object representing a GMMN (input and output
      layer are three-dimensional, the single hidden layer is
      300-dimensional) trained on 60000 pseudo-samples (with batch size 5000 and
      300 epochs) from a three-dimensional nested Gumbel copula
      (with sector dimensions 2 and 1, corresponding Kendall's tau 0.5
      within the first sector and Kendall's tau 0.25 between the two sectors).
    }
    \item{GMMN_dim_5_300_5_ntrn_60000_nbat_5000_nepo_300_C_tau_0.5}{
      \code{\link{raw}} \R object representing a GMMN (input and output
      layer are five-dimensional, the single hidden layer is
      300-dimensional) trained on 60000 pseudo-samples (with batch size 5000 and
      300 epochs) from a five-dimensional Clayton
      copula (with parameter chosen such that Kendall's tau equals 0.5).
    }
    \item{GMMN_dim_5_300_5_ntrn_60000_nbat_5000_nepo_300_G_tau_0.5}{
      \code{\link{raw}} \R object representing a GMMN (input and output
      layer are five-dimensional, the single hidden layer is
      300-dimensional) trained on 60000 pseudo-samples (with batch size 5000 and
      300 epochs) from a five-dimensional Gumbel
      copula (with parameter chosen such that Kendall's tau equals 0.5).
    }
    \item{GMMN_dim_5_300_5_ntrn_60000_nbat_5000_nepo_300_NC23_tau_0.25_0.5_0.75}{
      \code{\link{raw}} \R object representing a GMMN (input and output
      layer are five-dimensional, the single hidden layer is
      300-dimensional) trained on 60000 pseudo-samples (with batch size 5000 and
      300 epochs) from a five-dimensional nested Clayton copula
      (with sector dimensions 2 and 3, corresponding Kendall's tau 0.5
      and 0.75, and Kendall's tau 0.25 between the two sectors).
    }
    \item{GMMN_dim_5_300_5_ntrn_60000_nbat_5000_nepo_300_NG23_tau_0.25_0.5_0.75}{
      \code{\link{raw}} \R object representing a GMMN (input and output
      layer are five-dimensional, the single hidden layer is
      300-dimensional) trained on 60000 pseudo-samples (with batch size 5000 and
      300 epochs) from a five-dimensional nested Gumbel copula
      (with sector dimensions 2 and 3, corresponding Kendall's tau 0.5
      and 0.75, and Kendall's tau 0.25 between the two sectors);
      see \code{vignette("GMMN_QRNG", package = "gnn")}.
    }
    \item{GMMN_dim_5_300_5_ntrn_60000_nbat_5000_nepo_300_t4_tau_0.5}{
      \code{\link{raw}} \R object representing a GMMN (input and output
      layer are five-dimensional, the single hidden layer is
      300-dimensional) trained on 60000 pseudo-samples (with batch size 5000 and
      300 epochs) from a five-dimensional $t$ copula (with 4 degrees of freedom
      and equi-correlation parameter chosen such that Kendall's tau equals
      0.5); see \code{vignette("GMMN_QRNG", package = "gnn")}.
    }
    \item{GMMN_dim_10_300_10_ntrn_60000_nbat_5000_nepo_300_C_tau_0.5}{
      \code{\link{raw}} \R object representing a GMMN (input and output
      layer are 10-dimensional, the single hiddenlayer is
      300-dimensional) trained on 60000 pseudo-samples (with batch size 5000 and
      300 epochs) from a 10-dimensional Clayton
      copula (with parameter chosen such that Kendall's tau equals 0.5).
    }
    \item{GMMN_dim_10_300_10_ntrn_60000_nbat_5000_nepo_300_G_tau_0.5}{
      \code{\link{raw}} \R object representing a GMMN (input and output
      layer are 10-dimensional, the single hiddenlayer is
      300-dimensional) trained on 60000 pseudo-samples (with batch size 5000 and
      300 epochs) from a 10-dimensional Gumbel
      copula (with parameter chosen such that Kendall's tau equals 0.5).
    }
    \item{GMMN_dim_10_300_10_ntrn_60000_nbat_5000_nepo_300_NC55_tau_0.25_0.5_0.75}{
      \code{\link{raw}} \R object representing a GMMN (input and output
      layer are 10-dimensional, the single hidden layer is
      300-dimensional) trained on 60000 pseudo-samples (with batch size 5000 and
      300 epochs) from a 10-dimensional nested Clayton copula
      (with sector dimensions 5 and 5, corresponding Kendall's tau 0.5
      and 0.75, and Kendall's tau 0.25 between the two sectors).
    }
    \item{GMMN_dim_10_300_10_ntrn_60000_nbat_5000_nepo_300_NG55_tau_0.25_0.5_0.75}{
      \code{\link{raw}} \R object representing a GMMN (input and output
      layer are 10-dimensional, the single hidden layer is
      300-dimensional) trained on 60000 pseudo-samples (with batch size 5000 and
      300 epochs) from a 10-dimensional nested Gumbel copula
      (with sector dimensions 5 and 5, corresponding Kendall's tau 0.5
      and 0.75, and Kendall's tau 0.25 between the two sectors).
    }
    \item{GMMN_dim_10_300_10_ntrn_60000_nbat_5000_nepo_300_t4_tau_0.5}{
      \code{\link{raw}} \R object representing a GMMN (input and output
      layer are 10-dimensional, the single hidden layer is
      300-dimensional) trained on 60000 pseudo-samples (with batch size 5000 and
      300 epochs) from a 10-dimensional $t$ copula (with 4 degrees of freedom
      and equi-correlation parameter chosen such that Kendall's tau equals
      0.5).
    }
  }
}
\source{
  GPU server with NVIDIA Tesla P100 GPUs.
}
\author{Marius Hofert and Avinash Prasad}
\references{
  Hofert, M., Prasad, A. and Zhu, M. (2018).
  Quasi-Monte Carlo for multivariate distributions via generative neural networks.
  (See https://arxiv.org/abs/1811.00683 for an early version)
%% \emph{myjournal} \bold{myversion}(mynumber), --.
}
\seealso{
  \code{\link{GMMN_model}()}
}
\examples{
\donttest{
## Note: to_callable() below fails with "Error in load_model_hdf5(tmp,
## custom_objects = custom_objects, compile = compile) :
## The h5py Python package is required to save and load models"
## on win-builder which is the reason for \donttest{} here.

ngen <- 1000L # sample size of the generated data

## Generate a pseudo-sample from the mixture copula considered here
library(copula)
C.cop <- claytonCopula(iTau(claytonCopula(), tau = 0.5)) # Clayton copula
t.cop <- tCopula(iTau(tCopula(), tau = 0.5), df = 4) # t copula
t90.cop <- rotCopula(t.cop, flip = c(TRUE, FALSE)) # t copula rotated by 90 degrees
mix.cop <- mixCopula(list(C.cop, t90.cop), w = c(1/2, 1/2)) # the mixture copula
set.seed(271)
U.mix.PRNG <- rCopula(ngen, copula = mix.cop)

## Get the correspondingly trained GMMN
objname <- "GMMN_dim_2_300_2_ntrn_60000_nbat_5000_nepo_300_eqmix_C_tau_0.5_rot90_t4_tau_0.5"
read.GMMN <- read_rda(objname, file = objname, package = "gnn") # read in the trained GMMN
GMMN <- to_callable(read.GMMN) # convert to a callable GMMN object

## Generate an approximate pseudo- and quasi-sample from GMMN
## First, generate pseudo-random and quasi-random numbers from the prior distribution
N01.prior.PRNG <- matrix(rnorm(ngen * 2), ncol = 2) # N(0,1) PRNG
library(qrng)
N01.prior.QRNG <- qnorm(sobol(ngen, d = 2, randomize = "Owen")) # N(0,1) QRNG
## Now generate pseudo-random and quasi-random numbers from the fitted GMMN
U.mix.GMMN.PRNG <- pobs(predict(GMMN$model, x = N01.prior.PRNG))
U.mix.GMMN.QRNG <- pobs(predict(GMMN$model, x = N01.prior.QRNG))
## Note: For an explanation why pobs() is used, see Hofert, Prasad and Zhu (2018)

## Visualize the pseudo-random sample from the mixture copula, the pseudo-random
## sample from the trained GMMN and the quasi-random sample from the trained GMMN
layout(t(1:3)) # 1 x 3 layout
opar <- par(pty = "s") # square plots
plot(U.mix.PRNG,      main = "PRNG sample",      xlab = bquote(U[1]), ylab = bquote(U[2]))
plot(U.mix.GMMN.PRNG, main = "GMMN PRNG sample", xlab = bquote(U[1]), ylab = bquote(U[2]))
plot(U.mix.GMMN.QRNG, main = "GMMN QRNG sample", xlab = bquote(U[1]), ylab = bquote(U[2]))
par(opar)
layout(1)
}
}
\keyword{datasets}
