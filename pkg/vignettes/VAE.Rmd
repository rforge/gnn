---
title: Variational Autoencoders for Generating Images
author: Marius Hofert, Avinash Prasad
date: '`r Sys.Date()`'
output:
  html_vignette:
    css: style.css
vignette: >
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteIndexEntry{Variational Autoencoders for Generating Images}
  %\VignetteEncoding{UTF-8}
---
<!-- Train on Sharcnet's graham (GPU server) via sbatch start.sh, where the latter contains:
#!/bin/bash
#SBATCH --account=$USER
#SBATCH --mail-user=$USER@uwaterloo.ca
#SBATCH --mail-type=END
#SBATCH --gres=gpu:1          # request GPU "generic resource"
#SBATCH --cpus-per-task=16    # maximum CPU cores per GPU request (16 on Graham)
#SBATCH --mem=32G             # memory per node
#SBATCH --time=00-01:30       # time (DD-HH:MM)
#SBATCH --output=system.out # if %N-%j.out then %N is the node name, %j the jobID
module load gcc python/3.6 r/3.5.0
source ~/soft/keras_r/bin/activate
R CMD BATCH myscript.R
-->

## Introduction

This vignette demonstrates the application of variational autoencoders (VAEs; a type
of generative neural network) for the task of generating images. In particular,
we work with two standard image datasets, Frey faces and fashion-MNIST. The Frey
faces dataset contains 1965 images (with image size 20 by 28 pixels) of Brendan
Frey with different facial expressions and orientations. While a training sample
size of 1965 is relatively low compared to other popular datasets, it was
sufficient to train a VAE and generate realistic images. The
fashion-MNIST dataset contains 60000 images (which forms the training dataset)
of Zalando's article images (see
https://research.zalando.com/welcome/mission/research-projects/fashion-mnist/). This
dataset was created to replace the popular MNIST dataset of handwritten digits
often used as a benchmark dataset in the deep learning community. Like the MNIST
dataset, the fashion-MNIST dataset consists of images of size 28 by 28 pixels
(in grayscale) where each image is associated with a label from 10 classes. This
dataset was essentially created to provided a more challenging version of the
MNIST dataset while keeping the image size, number of classes, and training
dataset size the same.

Note that the neural networks were pre-trained on a GPU server (with NVIDIA
Tesla P100 GPUs) and we (re)use the generator component of the trained VAEs in
this vignette.

We start by loading the R packages we need.
```{r setup, message = FALSE}
## Packages
library(keras) # R interface to Keras (high-level neural network API)
library(tensorflow) # R interface to TensorFlow (numerical computation with tensors)
library(gnn) # for VAE model setup and saved VAE datasets
library(RnavGraphImageData) # for the Frey faces dataset
```


## 2 Frey faces

To begin with, we load the Frey faces training dataset.

```{r 2_definition_training_dataset}
data(frey)
## Adjust the dataset (so that each row represents a sample) and
## standardize it (so that pixel values are mapped to [0,1]; this helps
## training the VAE)
x.frey <- t(frey) / 255 # standardization
ntrn <- nrow(x.frey) # training dataset size
dim.in <- ncol(x.frey) # dimension of the training dataset
dim.out <- dim.in
```

Let us now visualize some images from the training dataset to get a picture of
our target distribution for the VAE.
```{r 2_plot, fig.align = "center", fig.width = 10, fig.height = 5.6, fig.show = "hold"}
## Plot
n.frey <- 10 # number of frey faces to display
nrow.frey <- 20 # number of rows of a single frey face
layout(matrix(1:n.frey, ncol = 5, byrow = TRUE))
for (i in 1:n.frey)
    plot(as.raster(t(matrix(x.frey[i,], nrow = nrow.frey))))
layout(1)
```

Next, we set up the VAE and train it based on the training dataset `x.frey`. The
generator component of the VAE is saved (or loaded using data() from `gnn`) to be
used later for generating Frey-type faces.
```{r 2_training}
## Training setup
nepo <- 300 # epochs (= passes through training dataset while updating NN parameters)
nbat <- 100 # training batch size (number of samples per stochastic gradient step)
dim.hidden <- 300 # dimension of single hidden layer
dim.lat <- 2 # dimension of latent layer
VAE.frey <- VAE_model(c(dim.in, dim.hidden, dim.lat)) # setup the VAE
objname <- paste0("VAE_gen_dim_",dim.lat,"_",dim.hidden,"_",dim.out,"_ntrn_",ntrn,
                  "_nbat_",nbat,"_nepo_",nepo,"_freyfaces")
## Train the VAE
if(dataset_exists(objname)) { # get trained VAE generator
    VAE.frey$generator <- unserialize_model(read_dataset(objname),compile=FALSE)
} else { # train the VAE and save the corresponding generator
    VAE.frey$model %>% fit(x.frey, x.frey, epochs = nepo, batch_size = nbat)
    save_rda(serialize_model(VAE.frey$generator), name = objname,
             file = paste0(objname,".rda"))
}
```

After training of the VAE, we can use it to generate Frey-type faces, that is,
we feed the learned generator component of the VAE with $\mathrm{N}(0,1)$
pseudo-random numbers (representing the latent layer). We then visualize the
generated images.
```{r 2_sampling_and_visualize, fig.align = "center", fig.width = 10, fig.height = 5.6, fig.show = "hold"}
set.seed(271) # for reproducibility
## Sample from the latent distribution
N01.latent <- matrix(rnorm(n.frey * dim.lat), ncol = dim.lat)
## Generate Frey faces from the fitted VAE
x.frey.VAE <- predict(VAE.frey$generator, N01.latent)
## Plot
layout(matrix(1:n.frey, ncol = 5, byrow = TRUE))
for (i in 1:n.frey)
    plot(as.raster(t(matrix(x.frey.VAE[i,], nrow = nrow.frey))))
layout(1)
```


## 3 Fashion-MNIST

To begin with, we load the fashion-MNIST training dataset.
```{r 3_definition_training_dataset}
fmnist <- dataset_fashion_mnist() # load the full fashion MNIST dataset from 'keras'
x.fmnist <- fmnist$train$x / 255 # standardize the dataset
x.fmnist <- t(apply(x.fmnist, 1, as.numeric)) # adjustment to create the appropriate traning dataset
ntrn <- nrow(x.fmnist) # training dataset size
dim.in <- ncol(x.fmnist) # dimension of training dataset
dim.out <- dim.in
```

Let us now visualize some images from the training dataset to get a picture of
our target distribution for the variational autoencoder.
```{r 3_plot, fig.align = "center", fig.width = 8, fig.height = 4, fig.show = "hold"}
## Plo
n.fmnist <- 10 # number of fashion-MNIST images to display
nrow.fmnist <- 28 # number of rows of a single fashion-MNIST image
layout(matrix(1:n.fmnist, ncol = 5, byrow = TRUE))
for (i in 1:n.fmnist)
    plot(as.raster(matrix(x.fmnist[i,], nrow = nrow.fmnist)))
layout(1)
```

Next, we set up the VAE and train it based on the training dataset
`x.fmnist`. Since we are working with a higher-dimensional and more complex
dataset (there is a greater variety of images when compared to the Frey faces),
we choose to work with a VAE with three hidden layers instead of one.
```{r 3_training}
## Training setup
nepo <- 100 # epochs (= passes through training dataset while updating NN parameters)
nbat <- 100 # training batch size (number of samples per stochastic gradient step)
dim.hidden <- 300 # dimension of the three hidden layers
dim.lat <- 2 # dimension of latent layer
VAE.fmnist <- VAE_model(c(dim.in, rep(dim.hidden, 3), dim.lat)) # setup the VAE
objname <- paste0("VAE_gen_dim_",dim.lat,"_3_",dim.hidden,"_",dim.out,"_ntrn_",ntrn,
                  "_nbat_",nbat,"_nepo_",nepo,"_fmnist")
## Train the VAE
if(dataset_exists(objname)) { # get trained VAE generator
    VAE.fmnist$generator <- unserialize_model(read_dataset(objname),compile=FALSE)
} else { # train the VAE and save the corresponding generator
    VAE.fmnist$model %>% fit(x.fmnist, x.fmnist, epochs = nepo, batch_size = nbat)
    save_rda(serialize_model(VAE.fmnist$generator), name = objname,
             file = paste0(objname,".rda"))
}
```

After training of the VAE, we can use it to generate fashion-MNIST-type images,
that is, we feed the learned generator component of the VAE with
$\mathrm{N}(0,1)$ pseudo-random numbers (representing the latent layer).  We
then visualize the generated images.
```{r 3_sampling_and_visualize, fig.align = "center", fig.width = 8, fig.height = 4, fig.show = "hold"}
## Sample from the latent distribution
N01.latent <- matrix(rnorm(n.fmnist * dim.lat), ncol = dim.lat)
# Generate Frey faces from the fitted VAE
x.fmnist.VAE <- predict(VAE.fmnist$generator, N01.latent)
## Plot
layout(matrix(1:n.fmnist, ncol = 5, byrow = TRUE))
for (i in 1:n.fmnist)
    plot(as.raster(matrix(x.fmnist.VAE[i,], nrow = nrow.fmnist)))
layout(1)
```

